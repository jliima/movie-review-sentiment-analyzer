{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical Assignment - Week 2\n",
    "- GitHub repo: https://github.com/jliima/movie-review-sentiment-analyzer\n",
    "- Demo video: https://www.youtube.com/watch?v=Q_YuPJ5Y2OU\n",
    "- Hugging Face Model: https://huggingface.co/hieroja/custom-sentiment-model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Dataset Preparation and Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Download the IMDB Dataset\n",
    "1. Use the IMDB dataset from Kaggle: ```/kaggle/input/imdb-dataset/IMDB Dataset.csv.```\n",
    "2. Load the dataset using Pandas and verify it in your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
      "License(s): other\n",
      "imdb-dataset-of-50k-movie-reviews.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
      "Archive:  imdb-dataset-of-50k-movie-reviews.zip\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "!kaggle datasets download -d 'lakshmi25npathi/imdb-dataset-of-50k-movie-reviews'\n",
    "!unzip -n 'imdb-dataset-of-50k-movie-reviews.zip' -d './data/'\n",
    "\n",
    "df = pd.read_csv('./data/IMDB Dataset.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Data Preprocessing\n",
    "1. Clean and preprocess the dataset:\n",
    "    - Encode the sentiment column (positive -> 1, negative -> 0).\n",
    "    - Retain only the review and label columns.\n",
    "2. Split the data into training and validation, testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainDf.shape: (40000, 2)\n",
      "valDf.shape: (9998, 2)\n",
      "testDf.shape: (2, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dfProcessed = df.copy()\n",
    "dfProcessed['sentiment'] = dfProcessed['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "dfProcessed = dfProcessed[['review', 'sentiment']]\n",
    "\n",
    "trainDf, tempDf = train_test_split(dfProcessed, test_size=0.2, random_state=42, stratify=dfProcessed['sentiment'])\n",
    "\n",
    "testPositive = tempDf[tempDf['sentiment'] == 1].sample(n=1, random_state=42)\n",
    "testNegative = tempDf[tempDf['sentiment'] == 0].sample(n=1, random_state=42)\n",
    "testDf = pd.concat([testPositive, testNegative])\n",
    "\n",
    "valDf = tempDf.drop(testDf.index)\n",
    "\n",
    "print('trainDf.shape:', trainDf.shape)\n",
    "print('valDf.shape:', valDf.shape)\n",
    "print('testDf.shape:', testDf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Model Selection and Tokenization\n",
    "1. Select a pre-trained Hugging Face transformer model for fine-tuning (e.g., distilbert-base-uncased).\n",
    "2. Tokenize the dataset with (see if required )\n",
    "    - Truncation.\n",
    "    - Padding.\n",
    "    - Maximum sequence length of 256."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f62cbbc0ce7d46f986a3cb8238fcd731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9142695b1cf047ba9fd955f555396e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9998 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5417fb34fed841e3b244e61fbc5f699f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "def tokenizeFunction(example):\n",
    "  return tokenizer(example['review'], padding='max_length', truncation=True, max_length=256)\n",
    "\n",
    "trainDataset = Dataset.from_pandas(trainDf)\n",
    "valDataset = Dataset.from_pandas(valDf)\n",
    "testDataset = Dataset.from_pandas(testDf)\n",
    "\n",
    "trainDataset = trainDataset.map(tokenizeFunction, batched=True)\n",
    "valDataset = valDataset.map(tokenizeFunction, batched=True)\n",
    "testDataset = testDataset.map(tokenizeFunction, batched=True)\n",
    "\n",
    "trainDataset = trainDataset.rename_column('sentiment', 'labels')\n",
    "valDataset = valDataset.rename_column('sentiment', 'labels')\n",
    "testDataset = testDataset.rename_column('sentiment', 'labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Fine-Tune the Model\n",
    "1. Fine-tune the model on the IMDB dataset for 2 epochs using the Hugging Face Trainer.\n",
    "2. Set training parameters:\n",
    "    - Learning rate: 5e-5 or your own\n",
    "    - Batch size: 16 or 32\n",
    "    - Evaluation at the end of each epoch.\n",
    "3. Ensure that metrics like accuracy, precision, recall, and F1-score are logged during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-11 23:07:29,952] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5000' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5000/5000 10:26, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.283000</td>\n",
       "      <td>0.221941</td>\n",
       "      <td>0.915283</td>\n",
       "      <td>0.903734</td>\n",
       "      <td>0.929586</td>\n",
       "      <td>0.916478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.143700</td>\n",
       "      <td>0.269158</td>\n",
       "      <td>0.919984</td>\n",
       "      <td>0.917645</td>\n",
       "      <td>0.922785</td>\n",
       "      <td>0.920207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5000, training_loss=0.21331258544921874, metrics={'train_runtime': 627.0555, 'train_samples_per_second': 127.58, 'train_steps_per_second': 7.974, 'total_flos': 5298695946240000.0, 'train_loss': 0.21331258544921874, 'epoch': 2.0})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "def computeMetrics(evalPred):\n",
    "  logits, labels = evalPred\n",
    "  predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "  accuracy = accuracy_score(labels, predictions)\n",
    "  precision = precision_score(labels, predictions)\n",
    "  recall = recall_score(labels, predictions)\n",
    "  f1 = f1_score(labels, predictions)\n",
    "\n",
    "  return {\n",
    "    'accuracy': accuracy, \n",
    "    'precision': precision, \n",
    "    'recall': recall, \n",
    "    'f1': f1\n",
    "  }\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "  'distilbert-base-uncased', \n",
    "  num_labels=2\n",
    ")\n",
    "\n",
    "trainingArgs = TrainingArguments(\n",
    "  output_dir='./results',\n",
    "  num_train_epochs=2,\n",
    "  per_device_train_batch_size=16,\n",
    "  per_device_eval_batch_size=16,\n",
    "  learning_rate=5e-5, #5e-5\n",
    "  eval_strategy='epoch',\n",
    "  save_strategy='epoch',\n",
    "  logging_strategy='epoch',\n",
    "  logging_dir='./logs'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "  model=model,\n",
    "  args=trainingArgs,\n",
    "  train_dataset=trainDataset,\n",
    "  eval_dataset=valDataset,\n",
    "  compute_metrics=computeMetrics\n",
    ")\n",
    "\n",
    "trainer.train(resume_from_checkpoint=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Save and Upload the Model to Hugging Face\n",
    "1. Save the fine-tuned model and tokenizer locally using save_pretrained().\n",
    "2. Log in to Hugging Face using notebook_login.\n",
    "3. Upload the model to Hugging Face using push_to_hub.\n",
    "4. Verify the model on Hugging Face Hub and include the link in your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4a3c1edd9c14694b8c9cef52b32082a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/hieroja/custom-sentiment-model/commit/f6b6a101e34329a510b9adbed581c5edfa36c8e8', commit_message='Upload tokenizer', commit_description='', oid='f6b6a101e34329a510b9adbed581c5edfa36c8e8', pr_url=None, repo_url=RepoUrl('https://huggingface.co/hieroja/custom-sentiment-model', endpoint='https://huggingface.co', repo_type='model', repo_id='hieroja/custom-sentiment-model'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "hfToken = os.getenv('HF_API_KEY')\n",
    "hfUsername = os.getenv('HF_USERNAME')\n",
    "\n",
    "model.save_pretrained('./custom-sentiment-model')\n",
    "tokenizer.save_pretrained('./custom-sentiment-model')\n",
    "\n",
    "model.push_to_hub(f'{hfUsername}/custom-sentiment-model', token=hfToken)\n",
    "tokenizer.push_to_hub(f'{hfUsername}/custom-sentiment-model', token=hfToken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: API Development and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps 6 7 and 9:\n",
    "#### **<span style=\"color:#00FF00\">SEE main.py for implementations!</span>**\n",
    "\n",
    "#### Step 6: Set Up the Backend API\n",
    "1. Use FastAPI or Flask, Express, Nest Nodejs to create an API.\n",
    "2. Define a POST endpoint (```/analyze/```) that:\n",
    "    - Accepts:\n",
    "      - ```text```: The input text for sentiment analysis.\n",
    "      - ```model```: A parameter specifying the model to use (```custom``` or ```llama```).\n",
    "    - Returns:\n",
    "      - Sentiment (```positive``` or ```negative```).\n",
    "      - Confidence score.\n",
    "#### Step 7: Load Models\n",
    "1. Load the fine-tuned model from Hugging Face.\n",
    "2. Access the Llama 3 model using the Groq Cloud API.\n",
    "\n",
    "#### Step 9: Define the Llama 3 Prompt (1 point)\n",
    "1. Write a clear and reusable prompt for the Llama 3 model in Groq Cloud.\n",
    "\n",
    "  Example: can be improved more\n",
    "\n",
    "  \"Classify the sentiment of this text as positive or negative:\n",
    "  'This movie was fantastic'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API server is already running\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import subprocess\n",
    "import psutil\n",
    "\n",
    "API_URL = 'http://127.0.0.1:8000/analyze/'\n",
    "SERVER_CMD = ['python', './backend/main.py']\n",
    "\n",
    "def killExistingServer():\n",
    "  for proc in psutil.process_iter(attrs=['pid', 'cmdline']):\n",
    "    if proc.info['cmdline'] and 'main.py' in proc.info['cmdline']:\n",
    "      print(f\"Stopping existing server (PID: {proc.info['pid']})...\")\n",
    "      proc.kill()\n",
    "      time.sleep(1)\n",
    "\n",
    "def isServerRunning():\n",
    "  try:\n",
    "    response = requests.get(API_URL.replace('/analyze/', '/docs'))\n",
    "    return response.status_code == 200\n",
    "  except requests.ConnectionError:\n",
    "    return False\n",
    "\n",
    "def startServer():\n",
    "  print('Starting API server...')\n",
    "  subprocess.Popen(SERVER_CMD, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "  time.sleep(2)\n",
    "\n",
    "  for _ in range(10):\n",
    "    if isServerRunning():\n",
    "      print('API server up and running!')\n",
    "      return\n",
    "    time.sleep(1)\n",
    "\n",
    "  raise RuntimeError('Failed to start API server.')\n",
    "\n",
    "\n",
    "if isServerRunning():\n",
    "  print('API server is already running')\n",
    "else:\n",
    "  startServer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps 8 and 10: \n",
    "#### Step 8: Test the API Locally\n",
    "1. Test the /analyze/ endpoint with both models (custom and llama) using:\n",
    "    - Postman.\n",
    "    - curl.\n",
    "    - Python requests.\n",
    "#### Step 10: Test with Both Models\n",
    "1. Verify that the API works for both the fine-tuned model and the Llama 3 model.\n",
    "2. Ensure the results return the sentiment score too.\n",
    "3. For Groq you can add into prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test case (model: custom):\n",
      "Review text: Many believe this movie is a baseball movie. Such people are disappointed because it's about a baseball player, but the movie isn't about baseball.<br /><br />Some think this movie is a romantic comedy and are disappointed because the relationship isn't really developed. This movie is not a romantic comedy.<br /><br />This movie is about culture. An arrogant American Major Leaguer and a stern traditional Japanese baseball manager cannot succeed because they can't, indeed, won't understand one another. It's after they manage to break through the cultural barrier that they have success. The ballplayer becomes more Japanese in his team mentality and the manager more American in allowing individual achievement, and they meet in the middle.<br /><br />Baseball and the romance is subordinate to this critique of the two cultures. Many who have no understanding of the Japanese mindset miss this and think it's a movie on baseball or romance and see the culture clash as mild comedy relief. It's not---the culture clash is the gravamen of the movie. Based on my own experience and understanding of the Japanese culture, I think this movie did quite well in that it didn't overly romanticize the Japanese culture nor overdo it in its portrayal.<br /><br />Overall, I believe this is an enjoyable and relaxing movie if one understands what it is really about.\n",
      "\n",
      "Expected sentiment: positive\n",
      "Response sentiment: positive (confidence 0.9955804944038391)\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Test case (model: llama):\n",
      "Review text: Many believe this movie is a baseball movie. Such people are disappointed because it's about a baseball player, but the movie isn't about baseball.<br /><br />Some think this movie is a romantic comedy and are disappointed because the relationship isn't really developed. This movie is not a romantic comedy.<br /><br />This movie is about culture. An arrogant American Major Leaguer and a stern traditional Japanese baseball manager cannot succeed because they can't, indeed, won't understand one another. It's after they manage to break through the cultural barrier that they have success. The ballplayer becomes more Japanese in his team mentality and the manager more American in allowing individual achievement, and they meet in the middle.<br /><br />Baseball and the romance is subordinate to this critique of the two cultures. Many who have no understanding of the Japanese mindset miss this and think it's a movie on baseball or romance and see the culture clash as mild comedy relief. It's not---the culture clash is the gravamen of the movie. Based on my own experience and understanding of the Japanese culture, I think this movie did quite well in that it didn't overly romanticize the Japanese culture nor overdo it in its portrayal.<br /><br />Overall, I believe this is an enjoyable and relaxing movie if one understands what it is really about.\n",
      "\n",
      "Expected sentiment: positive\n",
      "Response sentiment: positive (confidence 0.92)\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Test case (model: custom):\n",
      "Review text: In its way, Mister Foe (originally, and more appropriately, titled Hallam Foe  I can't see addressing its title character as \"mister\"), is a tribute to good acting. Both Jamie Bell, as Hallam, a physically attractive voyeur/creep, and Sophia Myles, as Kate, his kinky partner in sex and fantasy romance, are convincing. The problem comes when you try to connect their roles to anything that happens in real life. A young man who spies on the intimate details of people's lives the way Hallam does would be deservedly beaten to a pulp. And a woman in Kate's situation would be repulsed and frightened - she would probably call the police.<br /><br />These things are not, however, what happens in the movie. Poor Hallam's mother has died and his father married a woman with whom he's been having an affair. Hallam, of course, hates his stepmother and lets he know it. She has sex with him. Kate's some kind of an employment person who places Hallam in a dish washing job and plays sexual games. She looks like his birth mother. It all ends happily with Hallam \"resolving\" his \"issues\".<br /><br />Forty some years ago, the play and brilliantly acted movie, Who's Afraid of Virginia Woolf, had a similarly optimistic ending, with characters becoming wiser and better after tearing each other apart. The trouble is, it doesn't always work that way, especially when nobody really cares. In Virginia Woolf, the ending's plausible because of the intensity of the emotional revelation. In Mister Foe, the emotional revelation never really happens.\n",
      "\n",
      "Expected sentiment: negative\n",
      "Response sentiment: positive (confidence 0.8763022422790527)\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Test case (model: llama):\n",
      "Review text: In its way, Mister Foe (originally, and more appropriately, titled Hallam Foe  I can't see addressing its title character as \"mister\"), is a tribute to good acting. Both Jamie Bell, as Hallam, a physically attractive voyeur/creep, and Sophia Myles, as Kate, his kinky partner in sex and fantasy romance, are convincing. The problem comes when you try to connect their roles to anything that happens in real life. A young man who spies on the intimate details of people's lives the way Hallam does would be deservedly beaten to a pulp. And a woman in Kate's situation would be repulsed and frightened - she would probably call the police.<br /><br />These things are not, however, what happens in the movie. Poor Hallam's mother has died and his father married a woman with whom he's been having an affair. Hallam, of course, hates his stepmother and lets he know it. She has sex with him. Kate's some kind of an employment person who places Hallam in a dish washing job and plays sexual games. She looks like his birth mother. It all ends happily with Hallam \"resolving\" his \"issues\".<br /><br />Forty some years ago, the play and brilliantly acted movie, Who's Afraid of Virginia Woolf, had a similarly optimistic ending, with characters becoming wiser and better after tearing each other apart. The trouble is, it doesn't always work that way, especially when nobody really cares. In Virginia Woolf, the ending's plausible because of the intensity of the emotional revelation. In Mister Foe, the emotional revelation never really happens.\n",
      "\n",
      "Expected sentiment: negative\n",
      "Response sentiment: negative (confidence 0.854)\n",
      "---------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "labelMapping = {1: 'positive', 0: 'negative'}\n",
    "\n",
    "\n",
    "\n",
    "for i in range(2):\n",
    "  example = testDataset[i]\n",
    "  reviewText = example['review']\n",
    "  expectedSentiment = labelMapping[example['labels']]\n",
    "  \n",
    "  for model in ['custom', 'llama']:\n",
    "\n",
    "    response = requests.post(\n",
    "      url='http://localhost:8000/analyze/', \n",
    "      json={\n",
    "        'text': reviewText, \n",
    "        'model': model\n",
    "      }\n",
    "    )\n",
    "\n",
    "    result = response.json()\n",
    "\n",
    "    sentiment = result.get('sentiment')\n",
    "    confidence = result.get('confidence')\n",
    "    \n",
    "    print('Test case (model: {}):'.format(model))\n",
    "    print('Review text: {}\\n'.format(reviewText))\n",
    "    print('Expected sentiment: {}'.format(expectedSentiment))\n",
    "    print('Response sentiment: {} (confidence {})\\n---------------------------------------------------------------\\n'.format(sentiment, confidence))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
